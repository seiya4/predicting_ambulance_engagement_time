{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddff757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from multi_freq_ldpy.pure_frequency_oracles.GRR import GRR_Client\n",
    "from diffprivlib.mechanisms import Geometric\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfebea49",
   "metadata": {},
   "source": [
    "# Privacy budget from 0.01 to 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d7c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# CONFIGURATIONS\n",
    "# ==========================================================\n",
    "\n",
    "# number of iterations\n",
    "nb_iter = 20\n",
    "\n",
    "# seed\n",
    "SEED = 42\n",
    "\n",
    "# folder's name\n",
    "folder_name = \"RF_PreGEOGRR_Eps_0.01_15\"\n",
    "\n",
    "# eps values\n",
    "eps_values = list(np.round(np.arange(0.1,1,0.1),2)) + list(np.round(np.arange(1,16,1),2))\n",
    "\n",
    "# target\n",
    "target = \"ind_avg\"\n",
    "\n",
    "# dico result all iters\n",
    "dico_result_all = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8b0c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.03333333333333333\n",
      "0.2 0.06666666666666667\n",
      "0.3 0.09999999999999999\n",
      "0.4 0.13333333333333333\n",
      "0.5 0.16666666666666666\n",
      "0.6 0.19999999999999998\n",
      "0.7 0.2333333333333333\n",
      "0.8 0.26666666666666666\n",
      "0.9 0.3\n",
      "1 0.3333333333333333\n",
      "2 0.6666666666666666\n",
      "3 1.0\n",
      "4 1.3333333333333333\n",
      "5 1.6666666666666667\n",
      "6 2.0\n",
      "7 2.3333333333333335\n",
      "8 2.6666666666666665\n",
      "9 3.0\n",
      "10 3.3333333333333335\n",
      "11 3.6666666666666665\n",
      "12 4.0\n",
      "13 4.333333333333333\n",
      "14 4.666666666666667\n",
      "15 5.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ITERATIONS\n",
    "# ==========================================================\n",
    "\n",
    "for eps_total in eps_values:\n",
    "    \n",
    "    # eps\n",
    "    eps_div = eps_total/3\n",
    "    print(eps_total, eps_div)\n",
    "    \n",
    "    # dico results\n",
    "    dico_result = {\"acc\":[],\n",
    "                   \"c0\":[],\n",
    "                   \"c1\":[],\n",
    "                   \"f1\":[],\n",
    "                   \"acc-more_vol-0\":[],\n",
    "                   \"acc-more_vol-0-0\":[],\n",
    "                   \"acc-more_vol-0-1\":[],\n",
    "                   \"acc-more_prof-1\":[],\n",
    "                   \"acc-more_prof-1-0\":[],\n",
    "                   \"acc-more_prof-1-1\":[],\n",
    "                   \"disparate\":[],\n",
    "                   \"smoothed\":[],\n",
    "                   \"average_odds\":[],\n",
    "                   \"equal_opportunity\":[],\n",
    "                   \"mean_difference\":[],\n",
    "                   \"consistency\":[],\n",
    "                  }\n",
    "\n",
    "    for niter in range(nb_iter):\n",
    "\n",
    "        name_iter = \"ITER_\"+str(niter)+\"_\"\n",
    "\n",
    "        # reading dataset\n",
    "        # -------------------------------------------------------\n",
    "        df = pd.read_csv(\"dataset_classification.csv\")\n",
    "        df[\"alert\"] = pd.to_datetime(df[\"alert\"])\n",
    "        df.sort_values(by=\"alert\", ascending=True, inplace=True)\n",
    "        \n",
    "        # update dico_result\n",
    "        # ------------------------------------------------------\n",
    "        dico_result.update({\"feat_\"+f:[] for f in set(df.columns)-{target}})\n",
    "\n",
    "        # divide train test\n",
    "        # -------------------------------------------------------\n",
    "        learn = df.loc[df[\"alert\"]<datetime(2021,7,1,0,0,0)]\n",
    "        test = df.loc[df[\"alert\"]>=datetime(2021,7,1,0,0,0)]\n",
    "        del learn[\"alert\"], test[\"alert\"]\n",
    "\n",
    "        # applying DP\n",
    "        # -------------------------------------------------------\n",
    "        # Geometric\n",
    "        sensitive_vars = [(eps_div, \"nb_spp\"), # eps , var\n",
    "                          (eps_div, \"nb_spv\"), # eps , var\n",
    "                         ]\n",
    "        for eps, var in sensitive_vars:\n",
    "            GEO_MECH = Geometric(epsilon=eps, sensitivity=1)\n",
    "            learn[var] = [np.array(GEO_MECH.randomise(input_data)).clip(0) for input_data in learn[var]]\n",
    "        \n",
    "        # GRR\n",
    "        sensitive_vars = [(eps_div, \"motif\"), # eps , var # motif\n",
    "                         ]\n",
    "        for eps, var in sensitive_vars:\n",
    "            k = len(learn[var].unique())\n",
    "            learn[var] = [GRR_Client(input_data, k, eps) for input_data in learn[var]]\n",
    "        \n",
    "        # updating ind_prof\n",
    "        learn[\"ind_prof\"] = learn.apply(lambda x: 1 if x.nb_spv > x.nb_spp else 0, axis=1)\n",
    "\n",
    "        # saving train test xy dataset\n",
    "        # -------------------------------------------------------\n",
    "        X_train = learn.drop(target, axis=1)\n",
    "        y_train = learn[target]\n",
    "        X_test = test.drop(target, axis=1)\n",
    "        y_test = test[target]\n",
    "        dico_dataset = {}\n",
    "        dico_dataset[\"X_train\"] = X_train\n",
    "        dico_dataset[\"y_train\"] = y_train\n",
    "        dico_dataset[\"X_test\"] = X_test\n",
    "        dico_dataset[\"y_test\"] = y_test\n",
    "        pickle.dump(dico_dataset, open(folder_name + \"/\" + name_iter+\"eps\"+str(eps_total)+\"_train_test_xy.dat\", \"wb\"))\n",
    "        del dico_dataset\n",
    "\n",
    "        # model statistics\n",
    "        # -------------------------------------------------------\n",
    "        # general\n",
    "        params = {'n_estimators': 200, 'max_depth': 14, 'max_features': 0.8, 'max_samples': 0.95, 'class_weight': {0: 1, 1: 2}}\n",
    "        best_data = {}\n",
    "        best_data.update(pickle.load(open(folder_name + \"/\" + name_iter+\"eps\"+str(eps_total)+\"_train_test_xy.dat\", \"rb\"))) \n",
    "        model = RandomForestClassifier(random_state=SEED,\n",
    "                                       n_jobs=-1)\n",
    "        model.set_params(**params)\n",
    "        model.fit(best_data[\"X_train\"], best_data[\"y_train\"])\n",
    "        y_pred = model.predict(best_data[\"X_test\"])\n",
    "        \n",
    "        # feature importance\n",
    "        importance = pd.Series(model.feature_importances_, index=best_data[\"X_train\"].columns)\n",
    "        importance = importance.to_dict()\n",
    "        for f in importance.keys():\n",
    "            dico_result[\"feat_\"+f].append(importance[f])\n",
    "        \n",
    "        # performance metrics of the model in general\n",
    "        acc = round(accuracy_score(best_data[\"y_test\"],y_pred)*100, 2)\n",
    "        cm = confusion_matrix(best_data[\"y_test\"], y_pred)\n",
    "        c0 = round(cm[0,0]/np.sum(cm[0])*100, 2)\n",
    "        c1 = round(cm[1,1]/np.sum(cm[1])*100, 2)\n",
    "        report = classification_report(best_data[\"y_test\"], y_pred, output_dict=True)\n",
    "        f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "        dico_result[\"acc\"].append(acc)\n",
    "        dico_result[\"c0\"].append(c0)\n",
    "        dico_result[\"c1\"].append(c1)\n",
    "        dico_result[\"f1\"].append(f1)\n",
    "\n",
    "        # performance metrics of the model by group\n",
    "        dfout = pd.DataFrame()\n",
    "        dfout[\"ind_prof\"] = best_data[\"X_test\"][\"ind_prof\"]\n",
    "        dfout[\"y_test\"] = best_data[\"y_test\"].values\n",
    "        dfout[\"y_pred\"] = y_pred\n",
    "        for cat_name, cat_sex in [(\"more_vol\", 0),\n",
    "                                  (\"more_prof\", 1)]:\n",
    "            dfaux = dfout.loc[dfout[\"ind_prof\"]==cat_sex]\n",
    "            acc = round(accuracy_score(dfaux[\"y_test\"].values, dfaux[\"y_pred\"].values)*100, 2)\n",
    "            cm = confusion_matrix(dfaux[\"y_test\"].values, dfaux[\"y_pred\"].values)\n",
    "            c0 = round(cm[0,0]/np.sum(cm[0])*100, 2)\n",
    "            c1 = round(cm[1,1]/np.sum(cm[1])*100, 2)\n",
    "            dico_result[\"acc-\"+cat_name+\"-\"+str(cat_sex)].append(acc)\n",
    "            dico_result[\"acc-\"+cat_name+\"-\"+str(cat_sex)+\"-0\"].append(c0)\n",
    "            dico_result[\"acc-\"+cat_name+\"-\"+str(cat_sex)+\"-1\"].append(c1)\n",
    "\n",
    "        # disparate impact\n",
    "        unpriv_df = dfout[dfout[\"ind_prof\"]==0] \n",
    "        unpriv_total = unpriv_df.shape[0]\n",
    "\n",
    "        priv_df = dfout[dfout[\"ind_prof\"]==1]\n",
    "        priv_total = priv_df.shape[0]\n",
    "\n",
    "        unpriv_outcomes = unpriv_df[unpriv_df[\"y_pred\"]==1].shape[0]\n",
    "        unpriv_ratio = unpriv_outcomes/unpriv_total\n",
    "\n",
    "        priv_outcomes = priv_df[priv_df[\"y_pred\"]==1].shape[0]\n",
    "        priv_ratio = priv_outcomes/priv_total\n",
    "\n",
    "        disparate_impact = unpriv_ratio/priv_ratio\n",
    "        dico_result[\"disparate\"].append(disparate_impact)\n",
    "    \n",
    "        # SEDF\n",
    "        privileged_groups = [{'ind_prof': 1}] \n",
    "        unprivileged_groups = [{'ind_prof': 0}] \n",
    "        ds = best_data['X_test'].copy()\n",
    "        ds[\"y_pred\"] = y_pred\n",
    "        binaryLabelDataset = BinaryLabelDataset(favorable_label=0,\n",
    "                                                unfavorable_label=1,\n",
    "                                                df=ds,\n",
    "                                                label_names=['y_pred'],\n",
    "                                                protected_attribute_names=['ind_prof'])\n",
    "        metric = BinaryLabelDatasetMetric(binaryLabelDataset, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "        smoothed = metric.smoothed_empirical_differential_fairness()\n",
    "        dico_result[\"smoothed\"].append(metric.smoothed_empirical_differential_fairness())\n",
    "\n",
    "    # saving final results per epsilon\n",
    "    dico_result_all[eps_total] = {k:round(np.mean(dico_result[k]),2) for k in dico_result.keys()}\n",
    "    \n",
    "# saving all results\n",
    "pickle.dump(dico_result_all, open(folder_name + \"/\" + \"dico_result_all.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba5a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
